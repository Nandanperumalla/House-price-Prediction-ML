{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üè† House Price Prediction - Exploratory Data Analysis\n",
        "\n",
        "This notebook provides a comprehensive exploratory data analysis (EDA) for the Zillow house price prediction dataset.\n",
        "\n",
        "## üìã Table of Contents\n",
        "1. [Data Loading and Basic Information](#data-loading)\n",
        "2. [Data Quality Assessment](#data-quality)\n",
        "3. [Univariate Analysis](#univariate-analysis)\n",
        "4. [Bivariate Analysis](#bivariate-analysis)\n",
        "5. [Multivariate Analysis](#multivariate-analysis)\n",
        "6. [Feature Engineering Insights](#feature-engineering)\n",
        "7. [Data Preprocessing Recommendations](#preprocessing-recommendations)\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Project Objective\n",
        "Predict house prices using historical data from the Zillow dataset based on various features like location, square footage, number of bedrooms/bathrooms, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Import our custom modules\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "from data_preprocessing import DataPreprocessor, create_sample_data\n",
        "\n",
        "print(\"üìö Libraries imported successfully!\")\n",
        "print(\"üîß Custom modules loaded!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Basic Information {#data-loading}\n",
        "\n",
        "Let's start by loading the dataset and understanding its structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the data preprocessor\n",
        "preprocessor = DataPreprocessor()\n",
        "\n",
        "# For this demo, we'll create sample data that mimics the Zillow dataset structure\n",
        "# In a real scenario, you would load the actual dataset:\n",
        "# df = preprocessor.load_data('../data/zillow.csv')\n",
        "\n",
        "# Create sample data for demonstration\n",
        "df = create_sample_data()\n",
        "\n",
        "print(\"üìä Sample dataset created!\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "# Display basic information\n",
        "preprocessor.basic_info(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display first few rows\n",
        "print(\"üîç First 5 rows of the dataset:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display dataset statistics\n",
        "print(\"üìà Dataset Statistics:\")\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Quality Assessment {#data-quality}\n",
        "\n",
        "Let's assess the quality of our data by examining missing values, duplicates, and data types.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "missing_data = df.isnull().sum()\n",
        "missing_percent = (missing_data / len(df)) * 100\n",
        "\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': missing_data,\n",
        "    'Missing Percentage': missing_percent\n",
        "})\n",
        "\n",
        "print(\"üîç Missing Values Analysis:\")\n",
        "print(missing_df[missing_df['Missing Count'] > 0])\n",
        "\n",
        "# Visualize missing values\n",
        "if missing_data.sum() > 0:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    missing_df[missing_df['Missing Count'] > 0].plot(kind='bar', y='Missing Percentage')\n",
        "    plt.title('Missing Values by Column')\n",
        "    plt.ylabel('Percentage Missing')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚úÖ No missing values found!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for duplicates\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"üîç Duplicate rows: {duplicates}\")\n",
        "\n",
        "# Check data types\n",
        "print(\"\\nüìä Data Types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Check for potential outliers using IQR method\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "print(f\"\\nüîç Numerical columns: {list(numerical_cols)}\")\n",
        "\n",
        "outlier_summary = {}\n",
        "for col in numerical_cols:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
        "    outlier_summary[col] = len(outliers)\n",
        "\n",
        "outlier_df = pd.DataFrame(list(outlier_summary.items()), columns=['Column', 'Outlier Count'])\n",
        "print(\"\\nüö® Outliers detected:\")\n",
        "print(outlier_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Univariate Analysis {#univariate-analysis}\n",
        "\n",
        "Let's examine the distribution of individual variables to understand their characteristics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create distribution plots for numerical variables\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "n_cols = len(numerical_cols)\n",
        "n_rows = (n_cols + 2) // 3  # 3 columns per row\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, 3, figsize=(15, 5*n_rows))\n",
        "axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 else axes\n",
        "\n",
        "for i, col in enumerate(numerical_cols):\n",
        "    if i < len(axes):\n",
        "        # Histogram\n",
        "        axes[i].hist(df[col].dropna(), bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "        axes[i].set_title(f'Distribution of {col}')\n",
        "        axes[i].set_xlabel(col)\n",
        "        axes[i].set_ylabel('Frequency')\n",
        "        axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "# Hide empty subplots\n",
        "for i in range(len(numerical_cols), len(axes)):\n",
        "    axes[i].set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Box plots for outlier detection\n",
        "fig, axes = plt.subplots(n_rows, 3, figsize=(15, 5*n_rows))\n",
        "axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 else axes\n",
        "\n",
        "for i, col in enumerate(numerical_cols):\n",
        "    if i < len(axes):\n",
        "        # Box plot\n",
        "        axes[i].boxplot(df[col].dropna())\n",
        "        axes[i].set_title(f'Box Plot of {col}')\n",
        "        axes[i].set_ylabel(col)\n",
        "        axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "# Hide empty subplots\n",
        "for i in range(len(numerical_cols), len(axes)):\n",
        "    axes[i].set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Bivariate Analysis {#bivariate-analysis}\n",
        "\n",
        "Let's examine relationships between variables, especially with our target variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "print(\"üîó Correlation Matrix:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Visualize correlation matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter plots for key relationships\n",
        "key_features = ['taxvaluedollarcnt', 'calculatedfinishedsquarefeet', 'bedroomcnt', 'bathroomcnt']\n",
        "target = 'logerror'\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, feature in enumerate(key_features):\n",
        "    if feature in df.columns and i < len(axes):\n",
        "        axes[i].scatter(df[feature], df[target], alpha=0.6, color='blue')\n",
        "        axes[i].set_xlabel(feature)\n",
        "        axes[i].set_ylabel(target)\n",
        "        axes[i].set_title(f'{target} vs {feature}')\n",
        "        axes[i].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Add correlation coefficient\n",
        "        corr = df[feature].corr(df[target])\n",
        "        axes[i].text(0.05, 0.95, f'Corr: {corr:.3f}', transform=axes[i].transAxes,\n",
        "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Multivariate Analysis {#multivariate-analysis}\n",
        "\n",
        "Let's explore more complex relationships and patterns in the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pair plot for key numerical variables\n",
        "key_vars = ['taxvaluedollarcnt', 'calculatedfinishedsquarefeet', 'bedroomcnt', 'bathroomcnt', 'logerror']\n",
        "available_vars = [var for var in key_vars if var in df.columns]\n",
        "\n",
        "if len(available_vars) >= 3:\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.pairplot(df[available_vars], diag_kind='hist', plot_kws={'alpha': 0.6})\n",
        "    plt.suptitle('Pair Plot of Key Variables', y=1.02)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Not enough variables available for pair plot\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive 3D scatter plot using Plotly\n",
        "if 'taxvaluedollarcnt' in df.columns and 'calculatedfinishedsquarefeet' in df.columns and 'logerror' in df.columns:\n",
        "    fig = px.scatter_3d(df, \n",
        "                        x='taxvaluedollarcnt', \n",
        "                        y='calculatedfinishedsquarefeet', \n",
        "                        z='logerror',\n",
        "                        color='bedroomcnt' if 'bedroomcnt' in df.columns else 'logerror',\n",
        "                        title='3D Scatter Plot: Price vs Square Footage vs Log Error',\n",
        "                        labels={'taxvaluedollarcnt': 'Tax Value ($)',\n",
        "                               'calculatedfinishedsquarefeet': 'Square Feet',\n",
        "                               'logerror': 'Log Error'})\n",
        "    fig.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Required columns not available for 3D plot\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Feature Engineering Insights {#feature-engineering}\n",
        "\n",
        "Let's explore potential new features that could improve our model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create engineered features\n",
        "df_engineered = df.copy()\n",
        "\n",
        "# Price per square foot\n",
        "if 'taxvaluedollarcnt' in df_engineered.columns and 'calculatedfinishedsquarefeet' in df_engineered.columns:\n",
        "    df_engineered['price_per_sqft'] = df_engineered['taxvaluedollarcnt'] / df_engineered['calculatedfinishedsquarefeet']\n",
        "    df_engineered['price_per_sqft'] = df_engineered['price_per_sqft'].replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Total rooms\n",
        "if 'bedroomcnt' in df_engineered.columns and 'bathroomcnt' in df_engineered.columns:\n",
        "    df_engineered['total_rooms'] = df_engineered['bedroomcnt'] + df_engineered['bathroomcnt']\n",
        "\n",
        "# Property age\n",
        "if 'yearbuilt' in df_engineered.columns:\n",
        "    current_year = 2023\n",
        "    df_engineered['property_age'] = current_year - df_engineered['yearbuilt']\n",
        "    df_engineered['property_age'] = df_engineered['property_age'].clip(lower=0)\n",
        "\n",
        "# Log transformations\n",
        "if 'taxvaluedollarcnt' in df_engineered.columns:\n",
        "    df_engineered['log_taxvaluedollarcnt'] = np.log1p(df_engineered['taxvaluedollarcnt'])\n",
        "\n",
        "if 'calculatedfinishedsquarefeet' in df_engineered.columns:\n",
        "    df_engineered['log_calculatedfinishedsquarefeet'] = np.log1p(df_engineered['calculatedfinishedsquarefeet'])\n",
        "\n",
        "print(\"üîß Feature engineering completed!\")\n",
        "print(f\"New features created: {[col for col in df_engineered.columns if col not in df.columns]}\")\n",
        "\n",
        "# Display correlation with target for new features\n",
        "new_features = [col for col in df_engineered.columns if col not in df.columns]\n",
        "if new_features and 'logerror' in df_engineered.columns:\n",
        "    print(\"\\nüìä Correlation of new features with target:\")\n",
        "    for feature in new_features:\n",
        "        corr = df_engineered[feature].corr(df_engineered['logerror'])\n",
        "        print(f\"{feature}: {corr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Data Preprocessing Recommendations {#preprocessing-recommendations}\n",
        "\n",
        "Based on our analysis, let's summarize key findings and recommendations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary of key findings\n",
        "print(\"üìã EDA SUMMARY AND RECOMMENDATIONS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\nüîç DATA QUALITY:\")\n",
        "print(f\"‚Ä¢ Dataset shape: {df.shape}\")\n",
        "print(f\"‚Ä¢ Missing values: {df.isnull().sum().sum()}\")\n",
        "print(f\"‚Ä¢ Duplicate rows: {df.duplicated().sum()}\")\n",
        "\n",
        "print(\"\\nüìä KEY INSIGHTS:\")\n",
        "if 'logerror' in df.columns:\n",
        "    print(f\"‚Ä¢ Target variable (logerror) range: {df['logerror'].min():.4f} to {df['logerror'].max():.4f}\")\n",
        "    print(f\"‚Ä¢ Target variable mean: {df['logerror'].mean():.4f}\")\n",
        "    print(f\"‚Ä¢ Target variable std: {df['logerror'].std():.4f}\")\n",
        "\n",
        "# Top correlations with target\n",
        "if 'logerror' in df.columns:\n",
        "    correlations = df.corr()['logerror'].abs().sort_values(ascending=False)\n",
        "    print(f\"\\nüîó TOP CORRELATIONS WITH TARGET:\")\n",
        "    for i, (feature, corr) in enumerate(correlations.head(6).items()):\n",
        "        if feature != 'logerror':\n",
        "            print(f\"  {i+1}. {feature}: {corr:.4f}\")\n",
        "\n",
        "print(\"\\nüõ†Ô∏è PREPROCESSING RECOMMENDATIONS:\")\n",
        "print(\"1. Handle missing values using median imputation\")\n",
        "print(\"2. Remove outliers using IQR method\")\n",
        "print(\"3. Apply log transformation to skewed features\")\n",
        "print(\"4. Create engineered features (price per sqft, total rooms, property age)\")\n",
        "print(\"5. Scale features using StandardScaler\")\n",
        "print(\"6. Consider feature selection based on correlation analysis\")\n",
        "\n",
        "print(\"\\nüéØ MODELING RECOMMENDATIONS:\")\n",
        "print(\"1. Start with Random Forest for baseline\")\n",
        "print(\"2. Try XGBoost for better performance\")\n",
        "print(\"3. Use cross-validation for robust evaluation\")\n",
        "print(\"4. Consider ensemble methods\")\n",
        "print(\"5. Focus on feature engineering for improvement\")\n",
        "\n",
        "print(\"\\n‚úÖ EDA COMPLETED SUCCESSFULLY!\")\n",
        "print(\"Ready to proceed with model training and evaluation.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
